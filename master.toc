\babel@toc {english}{}\relax 
\contentsline {chapter}{\numberline {1}Fundamentals}{5}{chapter.1}%
\contentsline {section}{\numberline {1.1}Linear Algebra}{5}{section.1.1}%
\contentsline {paragraph}{Matrix dot product}{5}{section*.2}%
\contentsline {subparagraph}{Special cases}{5}{section*.3}%
\contentsline {paragraph}{Orthogonality}{5}{section*.4}%
\contentsline {paragraph}{Similarity}{5}{section*.5}%
\contentsline {paragraph}{Eigen-decomposition}{5}{section*.6}%
\contentsline {paragraph}{Gradient rules}{5}{section*.7}%
\contentsline {section}{\numberline {1.2}Law of Large Numbers}{6}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Practical interpretation}{6}{subsection.1.2.1}%
\contentsline {section}{\numberline {1.3}Bayes's Rule}{6}{section.1.3}%
\contentsline {section}{\numberline {1.4}Fundamental theorem of expectation}{6}{section.1.4}%
\contentsline {section}{\numberline {1.5}Tower Property}{7}{section.1.5}%
\contentsline {chapter}{\numberline {2}Estimation Theory}{9}{chapter.2}%
\contentsline {section}{\numberline {2.1}Introduction to Data Analysis}{9}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Data Analysis}{9}{subsection.2.1.1}%
\contentsline {section}{\numberline {2.2}Bayes Estimation}{11}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Random variable approximation}{11}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}MMSE}{11}{subsection.2.2.2}%
\contentsline {section}{\numberline {2.3}Maximum Likelihood Estimation}{12}{section.2.3}%
\contentsline {section}{\numberline {2.4}Exercises}{14}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Maximum Likelihood}{14}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Mean estimation on homogeneous data}{14}{subsection.2.4.2}%
\contentsline {subsection}{\numberline {2.4.3}Variance estimation on homogeneous data}{16}{subsection.2.4.3}%
\contentsline {subsection}{\numberline {2.4.4}Mean estimation on heterogeneous data}{16}{subsection.2.4.4}%
\contentsline {subsection}{\numberline {2.4.5}MMSE}{21}{subsection.2.4.5}%
\contentsline {chapter}{\numberline {3}Regression}{29}{chapter.3}%
\contentsline {section}{\numberline {3.1}Model Based Regression}{29}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Connection between model-based and supervised}{31}{subsection.3.1.1}%
\contentsline {subsection}{\numberline {3.1.2}Benchmark performance}{33}{subsection.3.1.2}%
\contentsline {section}{\numberline {3.2}Supervised Parametric Regression}{35}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Simple Linear Regression}{35}{subsection.3.2.1}%
\contentsline {subsection}{\numberline {3.2.2}Assesing the accuracy of the model}{36}{subsection.3.2.2}%
\contentsline {subsection}{\numberline {3.2.3}Multiple Linear Regression}{37}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Supervised Non Parametric Regression}{42}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Consistency}{42}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Asymptotic methods}{43}{subsection.3.3.2}%
\contentsline {subsection}{\numberline {3.3.3}Naive-Kernel Estimator}{44}{subsection.3.3.3}%
\contentsline {subsection}{\numberline {3.3.4}Nearest-Neighbour Estimator}{45}{subsection.3.3.4}%
\contentsline {subsection}{\numberline {3.3.5}Consistency of the estimators}{45}{subsection.3.3.5}%
\contentsline {subsection}{\numberline {3.3.6}Conditions for consistency}{45}{subsection.3.3.6}%
\contentsline {subsubsection}{Consistency of the naive-kernel estimator}{46}{section*.32}%
\contentsline {subsubsection}{Consistency of the nearest-neighbour estimator}{47}{section*.34}%
\contentsline {section}{\numberline {3.4}Exercise}{47}{section.3.4}%
\contentsline {chapter}{\numberline {4}Linear Methods for Regression}{49}{chapter.4}%
\contentsline {section}{\numberline {4.1}Resampling Methods}{49}{section.4.1}%
\contentsline {section}{\numberline {4.2}Model Selection}{55}{section.4.2}%
\contentsline {section}{\numberline {4.3}Shrinkage Methods}{59}{section.4.3}%
\contentsline {chapter}{\numberline {5}Classification}{65}{chapter.5}%
\contentsline {section}{\numberline {5.1}Introduction}{65}{section.5.1}%
\contentsline {section}{\numberline {5.2}Model-Based Classification}{66}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Bayesian approach}{66}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Neyman-Pearson Criterion}{70}{subsection.5.2.2}%
\contentsline {section}{\numberline {5.3}Supervised Classification}{71}{section.5.3}%
\contentsline {section}{\numberline {5.4}Exercises}{74}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Exercise 1}{74}{subsection.5.4.1}%
\contentsline {chapter}{\numberline {6}Optimization}{79}{chapter.6}%
\contentsline {section}{\numberline {6.1}Optimization in data analysis}{79}{section.6.1}%
\contentsline {section}{\numberline {6.2}Problem assumptions}{80}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Lipschitz Continuity}{80}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Convexity}{80}{subsection.6.2.2}%
\contentsline {section}{\numberline {6.3}Gradient Descent}{83}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Gradient Descent Limitations}{83}{subsection.6.3.1}%
\contentsline {section}{\numberline {6.4}Stochastic Gradient Descent}{84}{section.6.4}%
\contentsline {chapter}{\numberline {7}Cluster Analysis}{87}{chapter.7}%
\contentsline {section}{\numberline {7.1}PCA}{87}{section.7.1}%
\contentsline {section}{\numberline {7.2}Clustering}{90}{section.7.2}%
